# 📚 Entropía de un texto como fuente de memoria nula

![Java](https://img.shields.io/badge/-Java-red?style=flat-square&logo=java)
![GitHub last commit](https://img.shields.io/github/last-commit/andresarguelles/SistemaParaCalcularFuenteDiscretaSinMemoria)

## 🎯 Objetivo

Este programa tiene por objeto estimar la probabilidad de las letras del alfabeto en cualquier idioma y la cantidad de información media que cada una de estas letras proporciona. Dicha estimación posibilita la realización de códigos más eficientes aplicados a los textos escritos en diferentes idiomas.

## 💡 ¿Por qué es útil?

La entropía es una medida de la incertidumbre, sorpresa o desorden; en el contexto de la teoría de la información, se utiliza para cuantificar la cantidad de información que se espera en un mensaje, en función de la probabilidad de aparición de cada uno de los símbolos que lo componen.

Al calcular la entropía de un texto, podemos obtener una medida de cuánta información se está transmitiendo. Esto puede ser útil en una variedad de aplicaciones, como la compresión de datos, la criptografía, la codificación de información, entre otros.

## 🚀 Uso

Para usar este programa, simplemente necesitas tener un archivo de texto o un documento de Word con el texto del que deseas calcular la entropía. El programa leerá el archivo, calculará la probabilidad de cada símbolo, y luego usará esa información para calcular la entropía, la información total, la redundancia y la eficiencia.

## 📝 Licencia

Este proyecto está bajo la Licencia MIT - mira el archivo [LICENSE.md](LICENSE.md) para detalles